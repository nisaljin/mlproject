{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Renewable Energy GCPBBB Grid Connected Photo Sensor Project\n",
    "\n",
    "This notebook implements the Machine Learning pipeline for optimizing renewable energy integration. \n",
    "It covers data generation, feature engineering, model training, and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score, classification_report\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Ensure output directories exist\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('output', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Generation\n",
    "We generate synthetic data to simulate Weather (Irradiance, Temperature), Grid Consumption, and Battery SoC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_data(n_samples: int, start_date: str = '2023-01-01') -> pd.DataFrame:\n",
    "    dates = pd.date_range(start=start_date, periods=n_samples, freq='min') \n",
    "    \n",
    "    # Synthetic Solar Irradiance (approximate diurnal cycle)\n",
    "    hour_of_day = dates.hour + dates.minute / 60.0\n",
    "    irradiance = np.maximum(0, 1000 * np.sin(np.pi * (hour_of_day - 6) / 12)) \n",
    "    noise = np.random.normal(0, 50, n_samples)\n",
    "    irradiance = np.maximum(0, irradiance + noise)\n",
    "    \n",
    "    # Synthetic Temperature\n",
    "    temperature = 20 + 10 * np.sin(np.pi * (hour_of_day - 9) / 12) + np.random.normal(0, 2, n_samples)\n",
    "    \n",
    "    # Synthetic Grid Consumption\n",
    "    consumption = 500 + 300 * np.sin(np.pi * (hour_of_day - 7) / 12)**2 + \\\n",
    "                  400 * np.sin(np.pi * (hour_of_day - 19) / 12)**2 + \\\n",
    "                  np.random.normal(0, 50, n_samples)\n",
    "    consumption = np.maximum(200, consumption)\n",
    "\n",
    "    # Synthetic Battery SoC\n",
    "    soc = np.zeros(n_samples)\n",
    "    soc[0] = 50.0\n",
    "    battery_capacity = 10000 # Wh\n",
    "    \n",
    "    for i in range(1, n_samples):\n",
    "        net_energy = (irradiance[i] * 0.2) - (consumption[i] * 0.1)\n",
    "        delta_soc = net_energy / battery_capacity * 100\n",
    "        new_soc = soc[i-1] + delta_soc\n",
    "        soc[i] = np.clip(new_soc, 0, 100)\n",
    "\n",
    "    data = pd.DataFrame({\n",
    "        'Timestamp': dates,\n",
    "        'Irradiance': irradiance,\n",
    "        'Temperature': temperature,\n",
    "        'Grid_Consumption': consumption,\n",
    "        'Battery_SoC': soc\n",
    "    })\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Generate 1 month of data\n",
    "n_samples = 1440 * 30 \n",
    "data = generate_synthetic_data(n_samples)\n",
    "print(f\"Generated {len(data)} samples.\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering\n",
    "We add time-based features and lag features to capture temporal dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df['Hour'] = df['Timestamp'].dt.hour\n",
    "    df['Minute'] = df['Timestamp'].dt.minute\n",
    "    return df\n",
    "\n",
    "def add_lag_features(df: pd.DataFrame, columns: list, lags: list) -> pd.DataFrame:\n",
    "    for col in columns:\n",
    "        for lag in lags:\n",
    "            df[f'{col}_lag_{lag}'] = df[col].shift(lag)\n",
    "    return df\n",
    "\n",
    "def preprocess_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = add_time_features(df)\n",
    "    df = add_lag_features(df, ['Irradiance', 'Grid_Consumption'], [1, 5, 15])\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "data_processed = preprocess_features(data.copy())\n",
    "print(f\"Data shape after preprocessing: {data_processed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Development\n",
    "\n",
    "### 3.1 Energy Predictor (Random Forest)\n",
    "Predicts the next step's Grid Consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Data for Regression\n",
    "data_reg = data_processed.copy()\n",
    "data_reg['Target_Consumption'] = data_reg['Grid_Consumption'].shift(-1)\n",
    "data_reg = data_reg.dropna()\n",
    "\n",
    "feature_cols_reg = [c for c in data_reg.columns if c not in ['Timestamp', 'Target_Consumption']]\n",
    "X_reg = data_reg[feature_cols_reg]\n",
    "y_reg = data_reg['Target_Consumption']\n",
    "\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_reg, y_reg, test_size=0.2, shuffle=False)\n",
    "\n",
    "scaler_reg = StandardScaler()\n",
    "X_train_reg_scaled = scaler_reg.fit_transform(X_train_reg)\n",
    "X_test_reg_scaled = scaler_reg.transform(X_test_reg)\n",
    "\n",
    "# Train Model\n",
    "model_reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model_reg.fit(X_train_reg_scaled, y_train_reg)\n",
    "\n",
    "# Evaluate\n",
    "y_pred_reg = model_reg.predict(X_test_reg_scaled)\n",
    "mae = mean_absolute_error(y_test_reg, y_pred_reg)\n",
    "print(f\"Grid Consumption MAE: {mae:.4f}\")\n",
    "\n",
    "# Save\n",
    "joblib.dump(model_reg, 'models/energy_predictor.pkl')\n",
    "joblib.dump(scaler_reg, 'models/scaler_reg.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Balancing Classifier (XGBoost)\n",
    "Predicts the optimal battery action: 0 (Discharge), 1 (Hold), 2 (Charge)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Balancing Logic (Labels)\n",
    "def get_balancing_signal(row):\n",
    "    generation = row['Irradiance'] * 0.2\n",
    "    consumption = row['Grid_Consumption'] * 0.1\n",
    "    soc = row['Battery_SoC']\n",
    "    \n",
    "    if soc < 20:\n",
    "        return 2 # Charge (Priority)\n",
    "    elif soc > 80:\n",
    "        return 0 # Discharge (Priority)\n",
    "    elif abs(generation - consumption) < 20: # Threshold for balance\n",
    "        return 1 # Hold\n",
    "    elif generation > consumption:\n",
    "        return 2 # Charge (Excess energy)\n",
    "    else:\n",
    "        return 0 # Discharge (Deficit)\n",
    "\n",
    "data_clf = data_processed.copy()\n",
    "data_clf['Signal'] = data_clf.apply(get_balancing_signal, axis=1)\n",
    "\n",
    "# Prepare Data for Classification\n",
    "feature_cols_clf = [c for c in data_clf.columns if c not in ['Timestamp', 'Signal']]\n",
    "X_clf = data_clf[feature_cols_clf]\n",
    "y_clf = data_clf['Signal']\n",
    "\n",
    "X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(X_clf, y_clf, test_size=0.2, shuffle=False)\n",
    "\n",
    "scaler_clf = StandardScaler()\n",
    "X_train_clf_scaled = scaler_clf.fit_transform(X_train_clf)\n",
    "X_test_clf_scaled = scaler_clf.transform(X_test_clf)\n",
    "\n",
    "# Train Model\n",
    "model_clf = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "model_clf.fit(X_train_clf_scaled, y_train_clf)\n",
    "\n",
    "# Evaluate\n",
    "y_pred_clf = model_clf.predict(X_test_clf_scaled)\n",
    "acc = accuracy_score(y_test_clf, y_pred_clf)\n",
    "print(f\"Balancing Classifier Accuracy: {acc:.4f}\")\n",
    "print(classification_report(y_test_clf, y_pred_clf))\n",
    "\n",
    "# Save\n",
    "joblib.dump(model_clf, 'models/balancing_classifier.pkl')\n",
    "joblib.dump(scaler_clf, 'models/scaler_clf.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualization\n",
    "Visualize the predictions and system behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(y_test_reg.values[:200], label='Actual Consumption', alpha=0.7)\n",
    "plt.plot(y_pred_reg[:200], label='Predicted Consumption', alpha=0.7)\n",
    "plt.title('Grid Consumption Prediction (First 200 Test Samples)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
